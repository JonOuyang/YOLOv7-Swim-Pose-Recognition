{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d057bea",
   "metadata": {},
   "source": [
    "# Final Product of Swim Pose Recognition & Feedback Program\n",
    "\n",
    "##### Massive thanks to my mentor Derrick Trinh and my advisor Professor Chang Choo of San Jose State University for their guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing utility modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    " \n",
    "# importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd861996",
   "metadata": {},
   "source": [
    "## Modified Pose Estimation Algorithm (YOLOv7 Pose Estimation Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_model():\n",
    "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
    "    # Put in inference mode\n",
    "    model.float().eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # half() turns predictions into float16 tensors\n",
    "        # which significantly lowers inference time\n",
    "        model.half().to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73215109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image):\n",
    "    # Resize and pad image\n",
    "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (567, 960, 3)\n",
    "    # Apply transforms\n",
    "    image = transforms.ToTensor()(image) # torch.Size([3, 567, 960])\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "    # Turn image into batch\n",
    "    image = image.unsqueeze(0) # torch.Size([1, 3, 567, 960])\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "    return output, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81567ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(output, image):\n",
    "    global fc, c, t, nK, lK, na, nc, e, v\n",
    "    output = non_max_suppression_kpt(output, \n",
    "                                     0.03, # Confidence Threshold\n",
    "                                     0.2, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    #0.03, 0.2\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "        #print(f'Frame Number: {fc}; Data Size: {output.shape}')\n",
    "    try:\n",
    "        t = output[0] #retrieves only first skeleton data\n",
    "        t = t[-36:] #cuts all head keypoints\n",
    "        #append all nose x coords\n",
    "        nK.append(t[0])\n",
    "        #appends all hip x coords\n",
    "        lK.append(t[18]) #array t is unsorted, the x values is every other starting at index 0 and y values every other starting at 1\n",
    "        #sets coordinate point as (0,0) if the algorithm is less than 20% confident in its prediction of said joint\n",
    "        for i in range(0, len(t), 3):\n",
    "            g = t[i:i+3]\n",
    "            if g[2] <= 0.20:\n",
    "                t[i] = 0\n",
    "                t[i+1] = 0\n",
    "                v+=1\n",
    "                e+=1\n",
    "        t = [x for i, x in enumerate(t) if (i+1)%3 != 0]\n",
    "        na.append(t)\n",
    "    except:\n",
    "        c += 1\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "    for idx in range(output.shape[0]):\n",
    "        plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "    return nimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce513016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(coordinates, ang):\n",
    "    #coordinates = np.array(coords)\n",
    "    #angles = np.random.uniform(low=-max_angle, high=max_angle)\n",
    "    angles = np.deg2rad(ang)\n",
    "    center = np.mean(coordinates, axis=(0, 1))  # Compute the center of rotation\n",
    "\n",
    "    rotation_matrix = np.array([[np.cos(angles), -np.sin(angles)],\n",
    "                                [np.sin(angles), np.cos(angles)]])\n",
    "\n",
    "    rotated_coordinates = np.zeros_like(coordinates)\n",
    "\n",
    "    for i in range(coordinates.shape[0]):\n",
    "        for j in range(coordinates.shape[1]):\n",
    "            # Translate coordinates to the center of rotation\n",
    "            translated_coord = coordinates[i, j] - center\n",
    "\n",
    "            # Apply rotation to the translated coordinates\n",
    "            rotated_coord = np.dot(rotation_matrix, translated_coord.T).T\n",
    "\n",
    "            # Translate back to the original position\n",
    "            rotated_coordinates[i, j] = rotated_coord + center\n",
    "\n",
    "    rotated_coordinates = rotated_coordinates.tolist()\n",
    "    return rotated_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 0\n",
    "fa = []\n",
    "e=0\n",
    "v=0\n",
    "fc = 1\n",
    "na = []\n",
    "actualKp = []\n",
    "c=0\n",
    "lK = []\n",
    "nK = []\n",
    "la = []\n",
    "def swimPose_estimate(filename, savepath):\n",
    "    global fc, c, t, nK, lK, na, fa, e, v\n",
    "    \n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    totalFrames = math.floor(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))/32)\n",
    "    print(f'TF: {totalFrames}')\n",
    "    i = 0\n",
    "    fa = []\n",
    "    e=0\n",
    "    \n",
    "    while i < totalFrames:\n",
    "        na = []\n",
    "        fc = 0\n",
    "        nK = []\n",
    "        lK = []\n",
    "        c=0\n",
    "        poseH(filename, \"none\", i*32)\n",
    "        print(f'Original data: {c} empty frames')\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        #Perm Rotations\n",
    "        fc = 0\n",
    "        c=0\n",
    "        v=0\n",
    "        if statistics.median(nK) > statistics.median(lK):\n",
    "            na = []\n",
    "            v=0\n",
    "            #print(\"needs counterclockwise rotation\")\n",
    "            poseH(filename, \"cc\", i*32)\n",
    "            #print(\"transformation completed\")\n",
    "            print(f'Counterclockwise rotation; {c} empty frames')\n",
    "            if c <= 5:\n",
    "                z = np.array(na)\n",
    "                z = np.reshape(z, (z.shape[0], 12, 2))\n",
    "                fa.extend(rotate(z, (-90)))\n",
    "                #print(v)\n",
    "            else:\n",
    "                print(\"too many missing frames, batch discarded\")\n",
    "        else:\n",
    "            na = []\n",
    "            #print(\"needs clockwise rotation\")\n",
    "            poseH(filename, \"c\", i*32)\n",
    "            #print(\"transformation completed\")\n",
    "            print(f'Clockwise rotation; {c} empty frames')\n",
    "            if c <= 5:\n",
    "                z = np.array(na)\n",
    "                z = np.reshape(z, (z.shape[0], 12, 2))\n",
    "                fa.extend(rotate(z, 90))\n",
    "                #print(v)\n",
    "            else:\n",
    "                print(\"too many missing frames, batch discarded\")\n",
    "            \n",
    "        i += 1\n",
    "        print(f'batch {i} complete')\n",
    "        \n",
    "    print(\"=======================================================\")\n",
    "    print(\"-----------Skeleton Data Extraction Complete-----------\")\n",
    "    print(\"=======================================================\")\n",
    "\n",
    "    x = np.array(fa)\n",
    "    x = np.reshape(x, (x.shape[0], 12, 2))\n",
    "    print(f'Array shape: {x.shape}')\n",
    "    np.save(savepath, x)\n",
    "    print(f'Data saved to: {savepath}')\n",
    "    print(f'{e} total coordinates voided')\n",
    "\n",
    "    print(\"=======================================================\")\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50421b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poseH(filename, rotation, currentFrame):\n",
    "    global fc, c, t, nK, lK, na\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    # VideoWriter for saving the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter('Free_Skel.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, currentFrame)\n",
    "    while fc < 32 and cap.isOpened():\n",
    "        (ret, frame) = cap.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            if rotation == \"cc\":\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            elif rotation == \"c\":\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif rotation == \"none\":\n",
    "                pass\n",
    "            output, frame = run_inference(frame)\n",
    "            frame = draw_keypoints(output, frame)\n",
    "            fc += 1\n",
    "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
    "            if rotation == \"cc\" or rotation == \"c\":\n",
    "                frame = cv2.resize(frame,(720,1280),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            else:\n",
    "                frame = cv2.resize(frame,(1280,720),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Pose estimation', frame)\n",
    "        else:\n",
    "            break\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805b0f6",
   "metadata": {},
   "source": [
    "## Load Desired Video From Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1acf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "video = \"C:/Users/jonso/OneDrive/Desktop/Testing Data 2.mp4\"\n",
    "path = 'skeleton_data.npy'\n",
    "swimPose_estimate(video, path)\n",
    "#counterclockwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adabbe5",
   "metadata": {},
   "source": [
    "## Model Loading\n",
    "This program utilizes a decision tree, with 12 total individual models. The axisBC series consists of 5 separately trained ResNET models. The shortAxis series consists of 5 separately trained Convolutional Neural Networks (CNNs) models. The longAxis series consists of 2 separately trained Dense Neural Networks (DNNs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f74074",
   "metadata": {},
   "outputs": [],
   "source": [
    "longAxisBC2 = tf.keras.models.load_model('testModel76')\n",
    "longAxisBC3 = tf.keras.models.load_model('testModel77')\n",
    "\n",
    "shortAxisBC0 = tf.keras.models.load_model('testModel81')\n",
    "shortAxisBC1 = tf.keras.models.load_model('testModel82')\n",
    "shortAxisBC2 = tf.keras.models.load_model('testModel83')\n",
    "shortAxisBC3 = tf.keras.models.load_model('testModel84')\n",
    "shortAxisBC4 = tf.keras.models.load_model('testModel85')\n",
    "\n",
    "axisBC0 = tf.keras.models.load_model('testModel90')\n",
    "axisBC1 = tf.keras.models.load_model('testModel91')\n",
    "axisBC2 = tf.keras.models.load_model('testModel92')\n",
    "axisBC3 = tf.keras.models.load_model('testModel93')\n",
    "axisBC4 = tf.keras.models.load_model('testModel94')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa42b88",
   "metadata": {},
   "source": [
    "## Decision Tree Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longAxisBC(data):\n",
    "    m0 = longAxisBC2.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    m1 = longAxisBC3.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    conf = [m0, m1]\n",
    "    conf_array = np.array(conf).reshape(-1, 2)\n",
    "    # Calculate the average of values at index 0 and index 1\n",
    "    conf_array = [np.mean(conf_array[:, 0]), np.mean(conf_array[:, 1])]  # Average of index 0 values\n",
    "    return np.argmax(conf_array)\n",
    "\n",
    "def shortAxisBC(data):\n",
    "    m0 = shortAxisBC0.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    m1 = shortAxisBC1.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    m2 = shortAxisBC2.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    m3 = shortAxisBC3.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    m4 = shortAxisBC4.predict(np.reshape(data, (1, 32, 12, 3)))\n",
    "    conf = [m0, m1, m2, m3, m4]\n",
    "    num_models = len(conf)  # Number of models\n",
    "\n",
    "    # Initialize a dictionary to store accumulated class probabilities\n",
    "    conf_array = np.array(conf).reshape(-1, 2)\n",
    "\n",
    "    # Calculate the average of values at index 0 and index 1\n",
    "    conf_array = [np.mean(conf_array[:, 0]), np.mean(conf_array[:, 1])]  # Average of index 0 values\n",
    "    return np.argmax(conf_array)\n",
    "def bothAxisBC(data):\n",
    "    x1 = np.argmax(shortAxisBC0.predict(np.reshape(data, (1, 32, 12, 3))), axis=1)\n",
    "    x2 = np.argmax(shortAxisBC1.predict(np.reshape(data, (1, 32, 12, 3))), axis=1)\n",
    "    x3 = np.argmax(shortAxisBC2.predict(np.reshape(data, (1, 32, 12, 3))), axis=1)\n",
    "    x4 = np.argmax(shortAxisBC3.predict(np.reshape(data, (1, 32, 12, 3))), axis=1)\n",
    "    x5 = np.argmax(shortAxisBC4.predict(np.reshape(data, (1, 32, 12, 3))), axis=1)\n",
    "    array = [x1, x2, x3, x4, x5]\n",
    "    c=0\n",
    "    count += 1\n",
    "    for i in array:\n",
    "        if i == [0]:\n",
    "            c+=1\n",
    "        else:\n",
    "            pass\n",
    "    if c >=3: #takes the majority vote of the model voting ensemble, returning 0 if Freestyle/Backstroke; returns 1 if Butterfly/Breastroke\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da340c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_check = []\n",
    "for data in x_test:\n",
    "    if bothAxisBC(data) == 0:\n",
    "        if longAxisBC(data) == 0:\n",
    "            #Type Check; Free 0 Back 1\n",
    "            y_check.append(0)\n",
    "        else:\n",
    "            y_check.append(1)\n",
    "    else:\n",
    "        if shortAxisBC(data) == 0:\n",
    "            y_check.append(3)\n",
    "        else:\n",
    "            y_check.append(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d3a5e",
   "metadata": {},
   "source": [
    "## Stroke Feedback Classes\n",
    "Each of the 4 swim strokes are divided into classes. Within each class are the respective functions taking in keypoint joint coordinates as input, and outputting 0 if there is no error detected and 1 if there is error detected. Depending on the error type and depending on the number of frames with an error or no error present, the batch will be labeled to have error present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle3pt(a, b, c):\n",
    "    \"\"\"Counterclockwise angle in degrees by turning from a to c around b\n",
    "        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "        math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd617476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class freestyle:\n",
    "    def elbowDrop(data):\n",
    "        return 0 if not ((60 < angle3pt(data[10], data[8], data[6]) < 300) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1\n",
    "    def kneeAngle(data):\n",
    "        return 0 if ((70 < angle3pt(data[6], data[8], data[10]) < 290) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1\n",
    "    def sinkHip(data):\n",
    "        return 0 if not ((130 < angle3pt(data[0], data[6], data[8] < 230)) or (130 < angle3pt(data[1], data[7], data[9]) < 230)) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class backstroke:\n",
    "    def kneeAngle(data):\n",
    "        return 0 if ((70 < angle3pt(data[6], data[8], data[10]) < 290) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1\n",
    "    def sinkHip(data):\n",
    "        return 0 if not ((130 < angle3pt(data[0], data[6], data[8] < 230)) or (130 < angle3pt(data[1], data[7], data[9]) < 230)) else 1\n",
    "    def straightArm(data):\n",
    "        return 1 if ((170 < angle3pt(data[0], data[2], data[4]) < 190) or (170 < angle3pt(data[1], data[3], data[5]) < 190)) else  0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd310ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class butterfly:\n",
    "    def elbowDrop(data):\n",
    "        return 0 if not ((60 < angle3pt(data[10], data[8], data[6]) < 300) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1\n",
    "    def kickAngle(data):\n",
    "        return 0 if ((70 < angle3pt(data[6], data[8], data[10]) < 290) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1\n",
    "    def chestDown(data):\n",
    "        return 0 if min(data[0][1], data[1][1]) < min(data[6][1], data[7][1]) else 1\n",
    "    def legsTogether(data):\n",
    "        return 0 if not ((30 < angle3pt(data[8], data[6], data[9]) < 330) or (30 < angle3pt(data[8], data[7], data[9]) < 330)) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dada2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class breastroke:\n",
    "    def noKick(data):\n",
    "        return 0 if ((70 < angle3pt(data[6], data[8], data[10]) < 290) or (90 < angle3pt(data[11], data[9], data[7]) < 270)) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class underwater:\n",
    "    def legsTogether(data):\n",
    "        return 0 if not ((30 < angle3pt(data[8], data[6], data[9]) < 330) or (30 < angle3pt(data[8], data[7], data[9]) < 330)) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863cfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dive:\n",
    "    def hips(data):\n",
    "        print(data[6][1])\n",
    "        return 0 if min(data[5][1], data[6][1]) <= min(data[0][1], data[1][1]) else 1\n",
    "    def kneeAngle(data):\n",
    "        return 0 if (90 < angle3pt(data[10], data[8], data[6]) < 270) or (90 < angle3pt(data[11], data[9], data[7]) < 270) else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1de6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8ae96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d25029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "fc = 1\n",
    "#na = np.empty((1, 51))\n",
    "na = []\n",
    "currentKeypoints = []\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ab1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_model():\n",
    "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
    "    # Put in inference mode\n",
    "    model.float().eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # half() turns predictions into float16 tensors\n",
    "        # which significantly lowers inference time\n",
    "        model.half().to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf6b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image):\n",
    "    # Resize and pad image\n",
    "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (567, 960, 3)\n",
    "    # Apply transforms\n",
    "    image = transforms.ToTensor()(image) # torch.Size([3, 567, 960])\n",
    "    if torch.cuda.is_available():\n",
    "        image = image.half().to(device)\n",
    "    # Turn image into batch\n",
    "    image = image.unsqueeze(0) # torch.Size([1, 3, 567, 960])\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "    return output, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e51103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(output, image):\n",
    "    global fc, c\n",
    "    output = non_max_suppression_kpt(output, \n",
    "                                     0.02, # Confidence Threshold\n",
    "                                     0.1, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    #0.2, 0.4\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "        #print(f'Frame Number: {fc}; Data Size: {output.shape}')\n",
    "    try:\n",
    "        t = output[0] #retrieves only first skeleton data\n",
    "        t = t[-51:] #retrieves last 51 elements\n",
    "        #t = t[::3] cuts every third element (confidence level)\n",
    "        t = [x for i, x in enumerate(t) if (i+1)%3 != 0]\n",
    "        na.append(t)\n",
    "        currentKeypoints = []\n",
    "    except:\n",
    "        #currentKeypoints = \n",
    "        c += 1\n",
    "        #na.append([null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null,null, null])\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx in range(output.shape[0]):\n",
    "        plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "    \n",
    "    \n",
    "        \n",
    "    return nimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "121b0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFrame = 0\n",
    "fCount = 1\n",
    "\n",
    "def swimPose_estimate(filename):\n",
    "    global fc\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, currentFrame)\n",
    "    \n",
    "    # VideoWriter for saving the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter('Free_Skel.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    while cap.isOpened():\n",
    "        (ret, frame) = cap.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            output, frame = run_inference(frame)\n",
    "            frame = draw_keypoints(output, frame)\n",
    "            \n",
    "            #frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            #frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            output, frame = run_inference(frame)\n",
    "            frame = draw_keypoints(output, frame)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            fc += 1 #\n",
    "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
    "            frame = cv2.resize(frame,(720,1280),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Pose estimation', frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6efca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation_video(filename):\n",
    "    global fc\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    # VideoWriter for saving the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter('Free_Skel.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    while cap.isOpened():\n",
    "        (ret, frame) = cap.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            #frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            #frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            output, frame = run_inference(frame)\n",
    "            print(frame.shape)\n",
    "            frame = draw_keypoints(output, frame)\n",
    "            fc += 1 #\n",
    "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
    "            frame = cv2.resize(frame,(1280,720),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Pose estimation', frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5784fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation_video2(filename):\n",
    "    global fc\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    # VideoWriter for saving the video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    out = cv2.VideoWriter('Free_Skel.mp4', fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "    while cap.isOpened():\n",
    "        (ret, frame) = cap.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            #frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            output, frame = run_inference(frame)\n",
    "            frame = draw_keypoints(output, frame)\n",
    "            fc += 1 #\n",
    "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
    "            frame = cv2.resize(frame,(720,720),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('Pose estimation', frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76af0291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "torch.Size([1, 3, 576, 960])\n",
      "(21, 17, 2)\n",
      "6 total empty frames\n"
     ]
    }
   ],
   "source": [
    "#video = \"C:/Users/jonso/OneDrive/Desktop/IMG_5498.MOV\"\n",
    "video = \"C:/Users/jonso/OneDrive/Desktop/Free Training Data.mp4\"\n",
    "na = []\n",
    "c=0\n",
    "pose_estimation_video(video)\n",
    "skelData = np.array(na)\n",
    "skelData = skelData.reshape(skelData.shape[0], 17, 2)\n",
    "print(skelData.shape)\n",
    "print(f'{c} total empty frames')\n",
    "#print(na)\n",
    "#print(skelData)\n",
    "#np.save('Fly_Skel_Training.npy', skelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40336a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14542, 17, 2)\n",
      "208 total empty frames\n",
      "[[[      278.5       516.5]\n",
      "  [     282.25       508.5]\n",
      "  [     272.25      509.25]\n",
      "  ...\n",
      "  [     285.25         899]\n",
      "  [        282       958.5]\n",
      "  [     283.25       958.5]]\n",
      "\n",
      " [[        280         508]\n",
      "  [     285.25         500]\n",
      "  [        273       500.5]\n",
      "  ...\n",
      "  [     281.25         871]\n",
      "  [     272.75         945]\n",
      "  [      270.5       949.5]]\n",
      "\n",
      " [[      279.5         523]\n",
      "  [      284.5         515]\n",
      "  [     272.25       516.5]\n",
      "  ...\n",
      "  [      290.5         878]\n",
      "  [     279.75       913.5]\n",
      "  [        272       916.5]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[     361.75       384.5]\n",
      "  [      365.5      378.75]\n",
      "  [      359.5      379.75]\n",
      "  ...\n",
      "  [        393         543]\n",
      "  [     350.75         585]\n",
      "  [     405.25       599.5]]\n",
      "\n",
      " [[      375.5         387]\n",
      "  [     377.25         382]\n",
      "  [     371.25      382.75]\n",
      "  ...\n",
      "  [     389.25       544.5]\n",
      "  [        349         588]\n",
      "  [     403.75       598.5]]\n",
      "\n",
      " [[     380.75      382.75]\n",
      "  [      380.5       378.5]\n",
      "  [     375.25      378.75]\n",
      "  ...\n",
      "  [     390.25         546]\n",
      "  [      359.5         593]\n",
      "  [      392.5       602.5]]]\n"
     ]
    }
   ],
   "source": [
    "#video = \"C:/Users/jonso/OneDrive/Desktop/IMG_5498.MOV\"\n",
    "video = \"C:/Users/jonso/OneDrive/Desktop/Free Training Data.mp4\"\n",
    "na = []\n",
    "c=0\n",
    "pose_estimation_video2(video)\n",
    "skelData = np.array(na)\n",
    "skelData = skelData.reshape(skelData.shape[0], 17, 2)\n",
    "print(skelData.shape)\n",
    "print(f'{c} total empty frames')\n",
    "#print(na)\n",
    "print(skelData)\n",
    "#np.save('Fly_Skel_Training.npy', skelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d47bb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03ad90a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 17, 2)\n",
      "0 total empty frames\n",
      "[[[        268      446.75]\n",
      "  [      267.5      437.75]\n",
      "  [        262         441]\n",
      "  ...\n",
      "  [        277       777.5]\n",
      "  [      330.5       889.5]\n",
      "  [     268.25         899]]\n",
      "\n",
      " [[      284.5       457.5]\n",
      "  [        283      449.75]\n",
      "  [      274.5       453.5]\n",
      "  ...\n",
      "  [        277       774.5]\n",
      "  [      336.5       885.5]\n",
      "  [     259.75         881]]\n",
      "\n",
      " [[     284.25       457.5]\n",
      "  [     282.75         450]\n",
      "  [      274.5      453.75]\n",
      "  ...\n",
      "  [        277       774.5]\n",
      "  [      336.5       885.5]\n",
      "  [     259.75         881]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[     283.75       469.5]\n",
      "  [     281.25       462.5]\n",
      "  [      281.5       464.5]\n",
      "  ...\n",
      "  [      279.5       760.5]\n",
      "  [        343         871]\n",
      "  [      265.5         873]]\n",
      "\n",
      " [[      261.5      439.25]\n",
      "  [     259.25         436]\n",
      "  [     258.75         439]\n",
      "  ...\n",
      "  [     277.25         762]\n",
      "  [      339.5       862.5]\n",
      "  [     265.75         864]]\n",
      "\n",
      " [[        276       461.5]\n",
      "  [     274.25       454.5]\n",
      "  [     273.75       456.5]\n",
      "  ...\n",
      "  [     276.25         763]\n",
      "  [        341         868]\n",
      "  [     265.25         872]]]\n"
     ]
    }
   ],
   "source": [
    "#video = \"C:/Users/jonso/OneDrive/Desktop/IMG_5498.MOV\"\n",
    "video = \"C:/Users/jonso/OneDrive/Desktop/Free Training Data.mp4\"\n",
    "na = []\n",
    "c=0\n",
    "swimPose_estimate(video)\n",
    "skelData = np.array(na)\n",
    "skelData = skelData.reshape(skelData.shape[0], 17, 2)\n",
    "print(skelData.shape)\n",
    "print(f'{c} total empty frames')\n",
    "#print(na)\n",
    "print(skelData)\n",
    "#np.save('Fly_Skel_Training.npy', skelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dbff19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(videoPath, savePath):\n",
    "    global fc, c, na, skelData\n",
    "    c=0\n",
    "    video = videoPath\n",
    "    na = []\n",
    "    pose_estimation_video(video)\n",
    "    skelData = np.array(na)\n",
    "    skelData = skelData.reshape(skelData.shape[0], 17, 2)\n",
    "    print(skelData.shape)\n",
    "    print(f'{c} total empty frames')\n",
    "    #print(na)\n",
    "    print(skelData[0])\n",
    "    np.save(savePath, skelData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fd95ea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13973, 17, 2)\n",
      "2226 total empty frames\n",
      "[[     58.906      180.62]\n",
      " [     64.375       172.5]\n",
      " [     48.688      171.38]\n",
      " [     70.562         178]\n",
      " [     26.406      175.75]\n",
      " [       78.5      218.12]\n",
      " [     11.016      214.25]\n",
      " [      96.25      258.25]\n",
      " [        7.5         257]\n",
      " [     66.625       263.5]\n",
      " [     17.562      260.75]\n",
      " [     65.188      276.25]\n",
      " [     22.391         275]\n",
      " [      98.25       255.5]\n",
      " [     29.688      257.75]\n",
      " [     49.844       262.5]\n",
      " [     30.797         263]]\n",
      "(19048, 17, 2)\n",
      "1976 total empty frames\n",
      "[[        524      339.75]\n",
      " [      517.5      334.25]\n",
      " [        521      343.25]\n",
      " [        525      322.25]\n",
      " [        528         337]\n",
      " [        567         308]\n",
      " [      563.5       325.5]\n",
      " [     505.75      287.25]\n",
      " [     496.25       298.5]\n",
      " [        447       270.5]\n",
      " [      445.5       275.5]\n",
      " [        632       309.5]\n",
      " [      627.5      319.75]\n",
      " [      563.5       285.5]\n",
      " [        557       295.5]\n",
      " [        513       271.5]\n",
      " [        501         294]]\n",
      "(11444, 17, 2)\n",
      "1355 total empty frames\n",
      "[[      463.5      278.75]\n",
      " [     465.75      276.25]\n",
      " [      461.5         276]\n",
      " [     474.25      274.25]\n",
      " [      459.5      276.75]\n",
      " [     483.75      274.25]\n",
      " [     467.25      278.75]\n",
      " [     500.75         271]\n",
      " [      455.5      275.75]\n",
      " [      498.5      290.25]\n",
      " [     460.75         289]\n",
      " [      523.5      281.25]\n",
      " [      513.5      284.25]\n",
      " [      545.5       290.5]\n",
      " [      536.5         290]\n",
      " [        570      288.25]\n",
      " [        560         288]]\n",
      "(8956, 17, 2)\n",
      "1213 total empty frames\n",
      "[[        471      224.75]\n",
      " [        473      227.25]\n",
      " [     475.75         226]\n",
      " [        481      224.38]\n",
      " [        506      210.12]\n",
      " [      476.5      218.75]\n",
      " [        490       216.5]\n",
      " [        530      210.75]\n",
      " [      521.5         203]\n",
      " [        621      202.25]\n",
      " [        604      204.25]\n",
      " [     355.75       230.5]\n",
      " [      359.5      226.25]\n",
      " [     249.62      263.75]\n",
      " [     255.75       265.5]\n",
      " [      160.5      290.25]\n",
      " [     163.88      292.25]]\n",
      "(1927, 17, 2)\n",
      "223 total empty frames\n",
      "[[        784      334.75]\n",
      " [      785.5      331.25]\n",
      " [        782      332.25]\n",
      " [      789.5       330.5]\n",
      " [        781       327.5]\n",
      " [        793       336.5]\n",
      " [      782.5         337]\n",
      " [        801      322.75]\n",
      " [        774         336]\n",
      " [      777.5      302.25]\n",
      " [        778      330.75]\n",
      " [        794         379]\n",
      " [        786         378]\n",
      " [        793         417]\n",
      " [      791.5      415.25]\n",
      " [        796       454.5]\n",
      " [        796         454]]\n",
      "(3054, 17, 2)\n",
      "30 total empty frames\n",
      "[[        427      305.25]\n",
      " [      420.5      299.25]\n",
      " [      424.5         302]\n",
      " [      421.5      277.75]\n",
      " [        431      273.25]\n",
      " [     441.25      277.25]\n",
      " [      459.5      269.25]\n",
      " [     449.75         363]\n",
      " [        483      354.75]\n",
      " [     456.75       431.5]\n",
      " [     475.75       424.5]\n",
      " [      559.5      231.38]\n",
      " [        561      236.62]\n",
      " [        521      325.25]\n",
      " [      516.5      330.25]\n",
      " [        618         376]\n",
      " [        516         433]]\n"
     ]
    }
   ],
   "source": [
    "preprocess('C:/Users/jonso/OneDrive/Desktop/Free Training Data.mp4', 'Free_Skel_Training.npy')\n",
    "preprocess(\"C:/Users/jonso/OneDrive/Desktop/Fly Training Data.mp4\", 'Fly_Skel_Training.npy')\n",
    "preprocess(\"C:/Users/jonso/OneDrive/Desktop/Back Training Data.mp4\", 'Back_Skel_Training.npy')\n",
    "preprocess(\"C:/Users/jonso/OneDrive/Desktop/Breast Training Data.mp4\", 'Breast_Skel_Training.npy')\n",
    "preprocess(\"C:/Users/jonso/OneDrive/Desktop/Underwater Training Data.mp4\", 'Underwater_Skel_Training.npy')\n",
    "preprocess(\"C:/Users/jonso/OneDrive/Desktop/Dive Training Data.mp4\", 'Dive_Skel_Training.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12094656",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Frame Number: 84; Data Size: (1, 58)\n",
    "        \n",
    "        batch_id, class_id, x, y, w, h, conf\n",
    "        \n",
    "[[          0           0      724.97      320.72      201.62      94.438     0.55844         \n",
    "  0 699       321.5     0.24487         \n",
    "  1 700      319.75     0.17566         \n",
    "  2 697         322    0.088501       \n",
    "  3 708.5      316.75     0.28247       \n",
    "  4 700.5      320.75     0.13757         \n",
    "  5 729         301     0.81641         \n",
    "  6 700        314.5      0.8335       \n",
    "  7 753.5      290.75     0.87598       \n",
    "  8 677.5      307.25     0.87158         \n",
    "  9 756        316.25     0.85107       \n",
    "  10 650.5      322        0.85352       \n",
    "  11 756.5      305        0.88818       \n",
    "  12 744.5      313.5      0.89648         \n",
    "  13 794        314.75     0.7168       \n",
    "  14 786.5      325.75     0.74707\n",
    "  15 792.5      307.5      0.67725         \n",
    "  16 785        307.5      0.70459]]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

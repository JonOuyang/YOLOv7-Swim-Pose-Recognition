{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d16e08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "307b8a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 64, 17, 2)\n",
      "(1858, 1)\n"
     ]
    }
   ],
   "source": [
    "FreeSkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/FreeSkel(64).npy\")\n",
    "FlySkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/FlySkel(64).npy\")\n",
    "BackSkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/BackSkel(64).npy\")\n",
    "BreastSkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/BreastSkel(64).npy\")\n",
    "UnderwaterSkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/UnderwaterSkel(64).npy\")\n",
    "DiveSkel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/DiveSkel(64).npy\")\n",
    "\n",
    "FreeLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/FreeLabel(64).npy\")\n",
    "FlyLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/FlyLabel(64).npy\")\n",
    "BackLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/BackLabel(64).npy\")\n",
    "BreastLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/BreastLabel(64).npy\")\n",
    "UnderwaterLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/UnderwaterLabel(64).npy\")\n",
    "DiveLabel = np.load(\"C:/Users/jonso/OneDrive/Desktop/yolov7-pose-estimation/DiveLabel(64).npy\")\n",
    "\n",
    "x_train = np.concatenate((FreeSkel, FlySkel, BackSkel, BreastSkel, UnderwaterSkel, DiveSkel, UnderwaterSkel))\n",
    "y_train = np.concatenate((FreeLabel, FlyLabel, BackLabel, BreastLabel, UnderwaterLabel, DiveLabel, UnderwaterLabel))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6deb1c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Assuming your array is named 'data'\\n# Shape of data: (576, 128, 17, 2)\\n\\n# Compute the sum of coordinates across the last axis (2)\\nsum_coordinates = np.sum(x_train, axis=-1)\\n\\n# Find the indices where sum of coordinates is not equal to 0\\nnonzero_indices = np.any(sum_coordinates != 0, axis=(-1, -2))\\n\\n# Filter the data array using the nonzero indices\\npreprocessed_data = x_train[nonzero_indices]\\n\\n# Shape of preprocessed_data: (num_groups, 128, 17, 2)\\n\\nprint(preprocessed_data.shape)\\n\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Assuming your array is named 'data'\n",
    "# Shape of data: (576, 128, 17, 2)\n",
    "\n",
    "# Compute the sum of coordinates across the last axis (2)\n",
    "sum_coordinates = np.sum(x_train, axis=-1)\n",
    "\n",
    "# Find the indices where sum of coordinates is not equal to 0\n",
    "nonzero_indices = np.any(sum_coordinates != 0, axis=(-1, -2))\n",
    "\n",
    "# Filter the data array using the nonzero indices\n",
    "preprocessed_data = x_train[nonzero_indices]\n",
    "\n",
    "# Shape of preprocessed_data: (num_groups, 128, 17, 2)\n",
    "\n",
    "print(preprocessed_data.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b10dcdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 64, 17, 2)\n",
      "(1858, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generate the same permutation indices\n",
    "permutation_indices = np.random.permutation(len(x_train))\n",
    "\n",
    "# Shuffle both arrays using the same permutation indices\n",
    "x_train = x_train[permutation_indices]\n",
    "y_train = y_train[permutation_indices]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "#print(x_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "59cc1fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1c590c68fd0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "input_shape = (64, 17, 2)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "def build_model3(pretrained=None):\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(64, (2,2), activation = 'relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (2,2), activation = 'relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (2,2), activation = 'relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Flatten(), layers.Dropout(0.5),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_weights(pretrained)\n",
    "    return model\n",
    "build_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b732288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 6)\n",
      "(1858, 64, 17, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eaed5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, sp, epochs=10):\n",
    "    batch_size = 2\n",
    "    #model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    #model.compile(loss=SparseCategoricalCrossEntropy(from_logits=True))\n",
    "    model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_split = 0.2)\n",
    "    #model.evaluate(x_test, y2_test, verbose=1)\n",
    "    model.save(sp)\n",
    "    print(\"-=- Model Saved -=-\")\n",
    "    #predicted_labels=np.argmax(model.predict(x_test), axis=1)\n",
    "    #confusion_mat = confusion_matrix(y_test, predicted_labels)\n",
    "    #print(confusion_mat)\n",
    "    #print(f'Model Accuracy based on testing data: {(np.trace(confusion_mat))/np.sum(confusion_mat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f74030f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "743/743 [==============================] - 7s 8ms/step - loss: 1.7577 - accuracy: 0.3022 - val_loss: 1.5446 - val_accuracy: 0.2608\n",
      "Epoch 2/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.5353 - accuracy: 0.3297 - val_loss: 1.6414 - val_accuracy: 0.3522\n",
      "Epoch 3/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.4039 - accuracy: 0.3950 - val_loss: 1.7837 - val_accuracy: 0.3978\n",
      "Epoch 4/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.3636 - accuracy: 0.4112 - val_loss: 1.9135 - val_accuracy: 0.2688\n",
      "Epoch 5/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.2977 - accuracy: 0.4502 - val_loss: 1.6115 - val_accuracy: 0.4113\n",
      "Epoch 6/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.1928 - accuracy: 0.5087 - val_loss: 1.8911 - val_accuracy: 0.4543\n",
      "Epoch 7/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 1.0364 - accuracy: 0.5458 - val_loss: 3.6641 - val_accuracy: 0.4220\n",
      "Epoch 8/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.8731 - accuracy: 0.6124 - val_loss: 1.5111 - val_accuracy: 0.5376\n",
      "Epoch 9/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.8678 - accuracy: 0.6245 - val_loss: 1.8269 - val_accuracy: 0.4462\n",
      "Epoch 10/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.7130 - accuracy: 0.6588 - val_loss: 1.9489 - val_accuracy: 0.5376\n",
      "Epoch 11/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.6808 - accuracy: 0.7086 - val_loss: 1.8864 - val_accuracy: 0.4704\n",
      "Epoch 12/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.6558 - accuracy: 0.7221 - val_loss: 2.3268 - val_accuracy: 0.5672\n",
      "Epoch 13/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.5502 - accuracy: 0.7665 - val_loss: 1.5407 - val_accuracy: 0.6613\n",
      "Epoch 14/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.5670 - accuracy: 0.7826 - val_loss: 1.9822 - val_accuracy: 0.6344\n",
      "Epoch 15/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.4781 - accuracy: 0.8203 - val_loss: 2.6056 - val_accuracy: 0.6882\n",
      "Epoch 16/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.4085 - accuracy: 0.8459 - val_loss: 4.8611 - val_accuracy: 0.5108\n",
      "Epoch 17/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.3870 - accuracy: 0.8573 - val_loss: 1.6195 - val_accuracy: 0.6882\n",
      "Epoch 18/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.3775 - accuracy: 0.8735 - val_loss: 2.5715 - val_accuracy: 0.6801\n",
      "Epoch 19/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.3279 - accuracy: 0.8923 - val_loss: 1.4206 - val_accuracy: 0.7231\n",
      "Epoch 20/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2419 - accuracy: 0.9179 - val_loss: 1.4316 - val_accuracy: 0.7392\n",
      "Epoch 21/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2598 - accuracy: 0.9132 - val_loss: 1.7895 - val_accuracy: 0.6935\n",
      "Epoch 22/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2094 - accuracy: 0.9266 - val_loss: 1.9177 - val_accuracy: 0.7366\n",
      "Epoch 23/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2766 - accuracy: 0.9031 - val_loss: 2.0265 - val_accuracy: 0.7366\n",
      "Epoch 24/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2244 - accuracy: 0.9186 - val_loss: 1.5642 - val_accuracy: 0.7312\n",
      "Epoch 25/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1780 - accuracy: 0.9341 - val_loss: 2.2476 - val_accuracy: 0.6694\n",
      "Epoch 26/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1799 - accuracy: 0.9415 - val_loss: 1.6399 - val_accuracy: 0.7392\n",
      "Epoch 27/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2035 - accuracy: 0.9334 - val_loss: 1.6479 - val_accuracy: 0.7715\n",
      "Epoch 28/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2005 - accuracy: 0.9347 - val_loss: 1.9970 - val_accuracy: 0.7285\n",
      "Epoch 29/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2582 - accuracy: 0.9246 - val_loss: 1.6884 - val_accuracy: 0.7554\n",
      "Epoch 30/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1319 - accuracy: 0.9556 - val_loss: 1.8361 - val_accuracy: 0.7527\n",
      "Epoch 31/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1967 - accuracy: 0.9448 - val_loss: 1.4854 - val_accuracy: 0.7608\n",
      "Epoch 32/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.2750 - accuracy: 0.9219 - val_loss: 1.7787 - val_accuracy: 0.7392\n",
      "Epoch 33/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1118 - accuracy: 0.9623 - val_loss: 2.0236 - val_accuracy: 0.7124\n",
      "Epoch 34/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1347 - accuracy: 0.9536 - val_loss: 1.7041 - val_accuracy: 0.7769\n",
      "Epoch 35/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1224 - accuracy: 0.9637 - val_loss: 1.9308 - val_accuracy: 0.6909\n",
      "Epoch 36/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1169 - accuracy: 0.9637 - val_loss: 1.4378 - val_accuracy: 0.7608\n",
      "Epoch 37/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1357 - accuracy: 0.9576 - val_loss: 1.8940 - val_accuracy: 0.7339\n",
      "Epoch 38/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1296 - accuracy: 0.9630 - val_loss: 3.5937 - val_accuracy: 0.6129\n",
      "Epoch 39/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1043 - accuracy: 0.9684 - val_loss: 1.7531 - val_accuracy: 0.7312\n",
      "Epoch 40/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1009 - accuracy: 0.9697 - val_loss: 1.3452 - val_accuracy: 0.7930\n",
      "Epoch 41/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1317 - accuracy: 0.9616 - val_loss: 1.5919 - val_accuracy: 0.7473\n",
      "Epoch 42/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1002 - accuracy: 0.9670 - val_loss: 1.5817 - val_accuracy: 0.7769\n",
      "Epoch 43/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1265 - accuracy: 0.9616 - val_loss: 1.8420 - val_accuracy: 0.7446\n",
      "Epoch 44/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1070 - accuracy: 0.9744 - val_loss: 1.8259 - val_accuracy: 0.7661\n",
      "Epoch 45/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0729 - accuracy: 0.9791 - val_loss: 1.4567 - val_accuracy: 0.7796\n",
      "Epoch 46/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0746 - accuracy: 0.9771 - val_loss: 1.3188 - val_accuracy: 0.8011\n",
      "Epoch 47/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0797 - accuracy: 0.9764 - val_loss: 1.7426 - val_accuracy: 0.7903\n",
      "Epoch 48/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1275 - accuracy: 0.9630 - val_loss: 1.7852 - val_accuracy: 0.7634\n",
      "Epoch 49/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0744 - accuracy: 0.9751 - val_loss: 2.0290 - val_accuracy: 0.7285\n",
      "Epoch 50/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 2.0784 - val_accuracy: 0.7339\n",
      "Epoch 51/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0974 - accuracy: 0.9771 - val_loss: 2.5909 - val_accuracy: 0.6909\n",
      "Epoch 52/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0725 - accuracy: 0.9771 - val_loss: 1.8142 - val_accuracy: 0.7634\n",
      "Epoch 53/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0951 - accuracy: 0.9751 - val_loss: 1.8368 - val_accuracy: 0.7661\n",
      "Epoch 54/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0478 - accuracy: 0.9812 - val_loss: 1.9083 - val_accuracy: 0.7715\n",
      "Epoch 55/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0768 - accuracy: 0.9805 - val_loss: 3.3043 - val_accuracy: 0.6747\n",
      "Epoch 56/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1196 - accuracy: 0.9724 - val_loss: 1.9663 - val_accuracy: 0.7634\n",
      "Epoch 57/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0655 - accuracy: 0.9805 - val_loss: 1.7702 - val_accuracy: 0.7769\n",
      "Epoch 58/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0644 - accuracy: 0.9838 - val_loss: 2.0685 - val_accuracy: 0.7473\n",
      "Epoch 59/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1007 - accuracy: 0.9764 - val_loss: 1.5682 - val_accuracy: 0.7608\n",
      "Epoch 60/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 1.6694 - val_accuracy: 0.7608\n",
      "Epoch 61/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1039 - accuracy: 0.9751 - val_loss: 2.4860 - val_accuracy: 0.7392\n",
      "Epoch 62/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0550 - accuracy: 0.9832 - val_loss: 1.5936 - val_accuracy: 0.7769\n",
      "Epoch 63/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0666 - accuracy: 0.9791 - val_loss: 1.4047 - val_accuracy: 0.7930\n",
      "Epoch 64/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0497 - accuracy: 0.9825 - val_loss: 1.9453 - val_accuracy: 0.7876\n",
      "Epoch 65/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0573 - accuracy: 0.9838 - val_loss: 2.2595 - val_accuracy: 0.7124\n",
      "Epoch 66/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1053 - accuracy: 0.9697 - val_loss: 2.1314 - val_accuracy: 0.7366\n",
      "Epoch 67/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0520 - accuracy: 0.9852 - val_loss: 1.6945 - val_accuracy: 0.7742\n",
      "Epoch 68/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0564 - accuracy: 0.9859 - val_loss: 1.8518 - val_accuracy: 0.7634\n",
      "Epoch 69/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0717 - accuracy: 0.9778 - val_loss: 1.9188 - val_accuracy: 0.7769\n",
      "Epoch 70/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0693 - accuracy: 0.9798 - val_loss: 2.0492 - val_accuracy: 0.7366\n",
      "Epoch 71/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1207 - accuracy: 0.9731 - val_loss: 1.7828 - val_accuracy: 0.7957\n",
      "Epoch 72/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0516 - accuracy: 0.9865 - val_loss: 1.7140 - val_accuracy: 0.7957\n",
      "Epoch 73/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0526 - accuracy: 0.9845 - val_loss: 1.6260 - val_accuracy: 0.7608\n",
      "Epoch 74/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 1.8840 - val_accuracy: 0.7581\n",
      "Epoch 75/75\n",
      "743/743 [==============================] - 6s 8ms/step - loss: 0.1298 - accuracy: 0.9711 - val_loss: 3.6062 - val_accuracy: 0.6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModel4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModel4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=- Model Saved -=-\n"
     ]
    }
   ],
   "source": [
    "train(build_model3(), \"testModel4\", epochs=75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a4175c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 10ms/step - loss: 0.1643 - accuracy: 0.9661\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.5523 - accuracy: 0.8525\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1826 - accuracy: 0.9633\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4327 - accuracy: 0.9124\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0708 - accuracy: 0.9778\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3125 - accuracy: 0.7931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3125228881835938, 0.7931034564971924]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testModel = tf.keras.models.load_model(\"testModel2\")\n",
    "testModel.summary\n",
    "#testModel.predict(FreeSkel)\n",
    "FL = keras.utils.to_categorical(FlyLabel, num_classes)\n",
    "testModel.evaluate(FlySkel, FL, verbose=1)\n",
    "FL = keras.utils.to_categorical(FreeLabel, num_classes)\n",
    "testModel.evaluate(FreeSkel, FL, verbose=1)\n",
    "FL = keras.utils.to_categorical(BackLabel, num_classes)\n",
    "testModel.evaluate(BackSkel, FL, verbose=1)\n",
    "FL = keras.utils.to_categorical(BreastLabel, num_classes)\n",
    "testModel.evaluate(BreastSkel, FL, verbose=1)\n",
    "FL = keras.utils.to_categorical(DiveLabel, num_classes)\n",
    "testModel.evaluate(DiveSkel, FL, verbose=1)\n",
    "FL = keras.utils.to_categorical(UnderwaterLabel, num_classes)\n",
    "testModel.evaluate(UnderwaterSkel, FL, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
